{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import geocoder\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify, send_file\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "app = Flask(__name__)\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Replace with your actual OpenAI API key\n",
    "client = OpenAI()\n",
    "\n",
    "def get_location():\n",
    "    g = geocoder.ip('me')\n",
    "    city = g.city\n",
    "    country = g.country\n",
    "    zipcode = g.postal\n",
    "    location_details = \"You are in \" + city + \", \" + country + \". Your zipcode is \" + zipcode + \".\"\n",
    "    return location_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime():\n",
    "    datetimeobject = datetime.now()\n",
    "    date = datetimeobject.strftime(\"%d-%m-%Y\")\n",
    "    time = datetimeobject.strftime(\"%H:%M:%S\")\n",
    "    date_time = \"Today's date is \" + date + \" and the time is \" + time + \".\"\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_image():\n",
    "    # Initialize the camera\n",
    "    cap = cv2.VideoCapture(0)  # '0' is typically the default value for the laptop's built-in webcam\n",
    "\n",
    "    # Check if the webcam is opened correctly\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Save the captured image to a file\n",
    "        cv2.imwrite('webcam_image.jpg', frame)\n",
    "        print(\"Image captured and saved successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to capture image\")\n",
    "\n",
    "    # Release the camera\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_click():\n",
    "    # Ask for permission to take a picture\n",
    "    permission = messagebox.askokcancel(\"Permission\", \"Do you want to take a picture?\")\n",
    "    if permission:\n",
    "        capture_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_camera():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Permission Request\")\n",
    "\n",
    "    button = tk.Button(root, text=\"Request Permission\", command=on_button_click)\n",
    "    button.pack(pady=20)\n",
    "\n",
    "    root.mainloop()\n",
    "    return(\"photo saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = client.files.create(\n",
    "    file=open(\"C:/Users/jatin/Downloads/SWE_Exhibitor_Information.pdf\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "        name=\"Exhibitor Assistant 1\",\n",
    "        instructions=\"You are an greeter at the SWE 2023 conference. Respond in a friendly manner.\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        tools=[\n",
    "            {\"type\": \"code_interpreter\"},\n",
    "            {\"type\":\"retrieval\"},\n",
    "            {\"type\": \"function\",\n",
    "             \"function\": {\n",
    "                 \"name\": \"get_location\",\n",
    "                 \"description\": \"Get the location of the user.\",\n",
    "                 \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                                \"user\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Name of the user\"\n",
    "                                },\n",
    "                        },\n",
    "                        \"required\": []\n",
    "                }\n",
    "            }\n",
    "            },\n",
    "            {\"type\": \"function\",\n",
    "             \"function\": {\n",
    "                 \"name\": \"get_datetime\",\n",
    "                 \"description\": \"Get the date and time of the user.\",\n",
    "                 \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                                \"user\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Name of the user\"\n",
    "                                },\n",
    "                        },\n",
    "                        \"required\": []\n",
    "                }\n",
    "            }\n",
    "            },\n",
    "            {\"type\": \"function\",\n",
    "             \"function\": {\n",
    "                 \"name\": \"use_camera\",\n",
    "                 \"description\": \"Use the webcam camera to capture an image of the user or any object in the frame of the webcam.\",\n",
    "                 \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                                \"user\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Name of the user\"\n",
    "                                },\n",
    "                        },\n",
    "                        \"required\": []\n",
    "                }\n",
    "            }\n",
    "            },\n",
    "        ],\n",
    "        file_ids=[file1.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"what location, date and time am I in? and take a picture of me\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "runStatus = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
    "print(runStatus.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_camera\n"
     ]
    }
   ],
   "source": [
    "print(runStatus.required_action.submit_tool_outputs.tool_calls[2].function.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(runStatus.required_action.submit_tool_outputs.tool_calls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are in Livonia, US. Your zipcode is 48150.']\n",
      "['You are in Livonia, US. Your zipcode is 48150.', \"Today's date is 25-11-2023 and the time is 17:30:05.\"]\n"
     ]
    }
   ],
   "source": [
    "msg = []\n",
    "if runStatus.required_action.submit_tool_outputs.tool_calls[0].function.name == \"get_location\":\n",
    "    msg.append(get_location())\n",
    "    print(msg)\n",
    "if runStatus.required_action.submit_tool_outputs.tool_calls[1].function.name == \"get_datetime\":\n",
    "    msg.append(get_datetime())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captured and saved successfully.\n",
      "[{'tool_call_id': 'call_kIxjWhBMsMy9BdLz2m9486s7', 'output': 'You are in Livonia, US. Your zipcode is 48150.'}, {'tool_call_id': 'call_4eYoB7Qz9mAXn5aCgnOQ7qHy', 'output': \"Today's date is 25-11-2023 and the time is 17:43:15.\"}, {'tool_call_id': 'call_8Ebw3Qz6TjjYpVt8VLZurC20', 'output': 'photo saved'}]\n"
     ]
    }
   ],
   "source": [
    "msg=[]\n",
    "tool_calls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "for i in range(len(tool_calls)):\n",
    "    if tool_calls[i].function.name == \"get_location\":\n",
    "        msg.append({\n",
    "            \"tool_call_id\": tool_calls[i].id,\n",
    "            \"output\": get_location()\n",
    "        })\n",
    "    if tool_calls[i].function.name == \"get_datetime\":\n",
    "        msg.append({\n",
    "            \"tool_call_id\": tool_calls[i].id,\n",
    "            \"output\": get_datetime()\n",
    "        })\n",
    "    if tool_calls[i].function.name == \"use_camera\":\n",
    "        msg.append({\n",
    "            \"tool_call_id\": tool_calls[i].id,\n",
    "            \"output\": use_camera()\n",
    "        })\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id,\n",
    "  tool_outputs=msg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently in Livonia, US, with the zipcode 48150. The date today is November 25, 2023, and the time is 17:43:15. And here's the picture I've taken of you:\n",
      "\n",
      "![Your Picture](sandbox:/mnt/data/photo.jpg)\n",
      "\n",
      "Please let me know if there is anything else I can assist you with!\n"
     ]
    }
   ],
   "source": [
    "responses = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "print(responses.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_5z8wxOex3OlbCknco6s42G47', assistant_id='asst_EEBLH3jtrvnxEOsyqA257CUA', cancelled_at=None, completed_at=1700617250, created_at=1700617228, expires_at=None, failed_at=None, file_ids=['file-xZG5vQ6pOV6kAbdgKkZgnDOu'], instructions='You are an greeter at the SWE 2023 conference.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1700617228, status='completed', thread_id='thread_uCJRH85vBY72HpPDwnPVjjMD', tools=[ToolAssistantToolsCode(type='code_interpreter'), ToolAssistantToolsRetrieval(type='retrieval')])\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "runStatus = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")\n",
    "print(runStatus)\n",
    "print(runStatus.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_WqI8hfd0c8ctz39kLvLa4kuu', assistant_id='asst_EEBLH3jtrvnxEOsyqA257CUA', content=[MessageContentText(text=Text(annotations=[], value='The SWE 2023 conference, also known as WE23, is themed \"Live Without Limits\" and is scheduled to take place from October 26-28, 2023 in Los Angeles, California. Some highlights of the conference include:\\n\\n- Interactive workshops focused on leadership and engineering.\\n- Opportunities for networking and gaining career insights.\\n- Engagement with industry leaders on innovation.\\n- Hands-on demonstrations and showcases of cutting-edge technology.\\n- Panel discussions on emerging trends and best practices.\\n- Sessions tailored for early-career professionals and aspiring leaders.\\n- Emphasis on nurturing growth, networking, and career development.\\n\\nThis event is a part of the Society of Women Engineers\\' mission to empower women in engineering and leadership, expand the image of the engineering profession, and demonstrate the value of diversity and inclusion. WE23 appears to be a major gathering aimed at supporting professional excellence and providing a global inclusive community for women in engineering and technology.'), type='text')], created_at=1700617242, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_5z8wxOex3OlbCknco6s42G47', thread_id='thread_uCJRH85vBY72HpPDwnPVjjMD'), ThreadMessage(id='msg_JJacfaggTTf2J7v0MnA5K6hs', assistant_id='asst_EEBLH3jtrvnxEOsyqA257CUA', content=[MessageContentText(text=Text(annotations=[], value='The SWE 2023 conference likely refers to an event organized by the Society of Women Engineers (SWE), a nonprofit educational and service organization that supports women to achieve their full potential in careers as engineers and leaders. Since the SWE holds annual conferences, this particular one would be for the year 2023.\\n\\nThese conferences typically include a wide range of activities, such as:\\n\\n1. Keynote speeches from prominent women in the engineering field.\\n2. Workshops and seminars focusing on professional development.\\n3. Career fairs providing networking opportunities with potential employers.\\n4. Technical presentations and papers from various engineering disciplines.\\n5. Award ceremonies recognizing the achievements of women engineers.\\n6. Sessions on outreach and advocacy for women in STEM.\\n\\nGiven the name and usual format of these events, the SWE 2023 conference would likely aim to connect women engineers, provide career guidance, showcase innovations and research, and discuss issues relevant to women in the STEM fields. \\n\\nSince I have a specific file that might contain information about the SWE 2023 conference, I can search within that file to provide you with more precise details about the event. Let\\'s start by searching the file for the term \"SWE 2023\" to locate relevant information.'), type='text')], created_at=1700617229, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_5z8wxOex3OlbCknco6s42G47', thread_id='thread_uCJRH85vBY72HpPDwnPVjjMD'), ThreadMessage(id='msg_nS991HcVXUE6LkhpGnv2dRhL', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='tell me about SWE 2023'), type='text')], created_at=1700617213, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_uCJRH85vBY72HpPDwnPVjjMD')], object='list', first_id='msg_WqI8hfd0c8ctz39kLvLa4kuu', last_id='msg_nS991HcVXUE6LkhpGnv2dRhL', has_more=False)\n",
      "[MessageContentText(text=Text(annotations=[], value='The SWE 2023 conference, also known as WE23, is themed \"Live Without Limits\" and is scheduled to take place from October 26-28, 2023 in Los Angeles, California. Some highlights of the conference include:\\n\\n- Interactive workshops focused on leadership and engineering.\\n- Opportunities for networking and gaining career insights.\\n- Engagement with industry leaders on innovation.\\n- Hands-on demonstrations and showcases of cutting-edge technology.\\n- Panel discussions on emerging trends and best practices.\\n- Sessions tailored for early-career professionals and aspiring leaders.\\n- Emphasis on nurturing growth, networking, and career development.\\n\\nThis event is a part of the Society of Women Engineers\\' mission to empower women in engineering and leadership, expand the image of the engineering profession, and demonstrate the value of diversity and inclusion. WE23 appears to be a major gathering aimed at supporting professional excellence and providing a global inclusive community for women in engineering and technology.'), type='text')]\n",
      "The SWE 2023 conference, also known as WE23, is themed \"Live Without Limits\" and is scheduled to take place from October 26-28, 2023 in Los Angeles, California. Some highlights of the conference include:\n",
      "\n",
      "- Interactive workshops focused on leadership and engineering.\n",
      "- Opportunities for networking and gaining career insights.\n",
      "- Engagement with industry leaders on innovation.\n",
      "- Hands-on demonstrations and showcases of cutting-edge technology.\n",
      "- Panel discussions on emerging trends and best practices.\n",
      "- Sessions tailored for early-career professionals and aspiring leaders.\n",
      "- Emphasis on nurturing growth, networking, and career development.\n",
      "\n",
      "This event is a part of the Society of Women Engineers' mission to empower women in engineering and leadership, expand the image of the engineering profession, and demonstrate the value of diversity and inclusion. WE23 appears to be a major gathering aimed at supporting professional excellence and providing a global inclusive community for women in engineering and technology.\n"
     ]
    }
   ],
   "source": [
    "responses = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n",
    "print(responses)\n",
    "print(responses.data[0].content)\n",
    "print(responses.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\jatin\\Documents\\AI\\base_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_working_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
